<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bayesian Detector Combination | KCL TAI Group </title> <meta name="author" content="KCL TAI Group "> <meta name="description" content="Object Detection with Noisy Crowdsourced (Multi-Rater) Annotations"> <meta name="keywords" content="statistical, machine-learning, jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kcl-tai.github.io/projects/bdc_eccv/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-bundle.min.css" integrity="sha256-yUoNxsvX+Vo8Trj3lZ/Y5ZBf8HlBFsB6Xwm7rH75/9E=" crossorigin="anonymous"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">KCL TAI Group</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/members/">Members </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/opening/">Openings </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Papers </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact">Contact </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header text-center"> <h1 class="post-title">Bayesian Detector Combination</h1> <h3 class="post-title text-center">Object Detection with Noisy Crowdsourced (Multi-Rater) Annotations</h3> <div class="post-description"> <p class="m-1"> <span><a href="https://zhiqin1998.github.io" class="link-primary" target="_blank" rel="external nofollow noopener">Zhi Qin Tan <sup>1</sup></a>  </span> <span><a href="https://olgaisupova.github.io" class="link-primary" target="_blank" rel="external nofollow noopener">Olga Isupova <sup>2</sup></a>  </span> <span><a href="https://www.surrey.ac.uk/people/gustavo-carneiro" class="link-primary" target="_blank" rel="external nofollow noopener">Gustavo Carneiro <sup>1</sup></a>  </span> <span><a href="https://x-up-lab.github.io" class="link-primary" target="_blank" rel="external nofollow noopener">Xiatian Zhu <sup>1</sup></a>  </span> <span><a href="https://yunpengli.ac/" class="link-primary" target="_blank" rel="external nofollow noopener">Yunpeng Li <sup>1,3</sup></a></span> <br> <span><sup>1</sup> University of Surrey  </span><span><sup>2</sup> University of Oxford  </span><span><sup>3</sup> King's College London</span><br> <span><a href="https://eccv2024.ecva.net/virtual/2024/poster/420" class="link-primary" target="_blank" rel="external nofollow noopener">European Conference on Computer Vision 2024</a></span> </p> <span class="link-block"> <a href="https://doi.org/10.1007/978-3-031-73036-8_19" target="_blank" class="btn btn-default rounded-pill p-2 px-3" rel="external nofollow noopener"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span><span class="link-block"> <a href="https://static-content.springer.com/esm/chp%3A10.1007%2F978-3-031-73036-8_19/MediaObjects/636743_1_En_19_MOESM1_ESM.pdf" target="_blank" class="btn btn-default rounded-pill p-2 px-3" rel="external nofollow noopener"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Supplementary</span> </a> </span><span class="link-block"> <a href="https://github.com/zhiqin1998/bdc" target="_blank" class="btn btn-default rounded-pill p-2 px-3" rel="external nofollow noopener"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Github</span> </a> </span><span class="link-block"> <a href="https://arxiv.org/abs/2407.07958" target="_blank" class="btn btn-default rounded-pill p-2 px-3" rel="external nofollow noopener"> <span class="icon"> <i class="ai ai-arxiv"></i> </span> <span>arXiv</span> </a> </span> </div> </header><hr> <div class="w-75 ml-0 mr-0 mx-auto"> <h3 class="post-title text-center">Abstract</h3> <div class="text-justify"> <p>Acquiring fine-grained object detection annotations in unconstrained images is time-consuming, expensive, and prone to noise, especially in crowdsourcing scenarios. Most prior object detection methods assume accurate annotations; A few recent works have studied object detection with noisy crowdsourced annotations, with evaluation on distinct synthetic crowdsourced datasets of varying setups under artificial assumptions. To address these algorithmic limitations and evaluation inconsistency, we first propose a novel Bayesian Detector Combination (BDC) framework to more effectively train object detectors with noisy crowdsourced annotations, with the unique ability of automatically inferring the annotators' label qualities. Unlike previous approaches, BDC is model-agnostic, requires no prior knowledge of the annotators' skill level, and seamlessly integrates with existing object detection models. Due to the scarcity of real-world crowdsourced datasets, we introduce large synthetic datasets by simulating varying crowdsourcing scenarios. This allows consistent evaluation of different models at scale. Extensive experiments on both real and synthetic crowdsourced datasets show that BDC outperforms existing state-of-the-art methods, demonstrating its superiority in leveraging crowdsourced data for object detection.</p> </div> </div> <hr style="height:10px;"> <article> <h3 id="noisy-crowdsourced-multi-rater-annotations"><strong>Noisy Crowdsourced (Multi-Rater Annotations)</strong></h3> <p>Accurate object annotations are often difficult and expensive to obtain. Researchers typically resorts to collecting crowdsourced or multi-rater annotations and perform aggregation to obtain better ground truth for model training. However, acquiring fine-grained object detection annotations in unconstrained images is time-consuming, expensive, and prone to noise. These challenges are especially significant in complex domains such as dental radiograph images, where interobserver variability and disagreement among expert annotators make it difficult to achieve unanimity.</p> <div class="w-50 ml-0 mr-0 mx-auto"> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true" centered-slides="true" autoplay-delay="5000"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/70282-480.webp 480w,/assets/img/bdc_eccv/70282-800.webp 800w,/assets/img/bdc_eccv/70282-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/70282.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy annotations in COCO dataset</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/326247-480.webp 480w,/assets/img/bdc_eccv/326247-800.webp 800w,/assets/img/bdc_eccv/326247-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/326247.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy annotations in COCO dataset</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/416149-480.webp 480w,/assets/img/bdc_eccv/416149-800.webp 800w,/assets/img/bdc_eccv/416149-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/416149.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy annotations in COCO dataset</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/disaster_110-480.webp 480w,/assets/img/bdc_eccv/disaster_110-800.webp 800w,/assets/img/bdc_eccv/disaster_110-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/disaster_110.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy crowdsourced annotations in a disaster response dataset</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/vindr_0-480.webp 480w,/assets/img/bdc_eccv/vindr_0-800.webp 800w,/assets/img/bdc_eccv/vindr_0-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/vindr_0.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy multi-rater annotations in VinDR-CXR dataset</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/vindr_62-480.webp 480w,/assets/img/bdc_eccv/vindr_62-800.webp 800w,/assets/img/bdc_eccv/vindr_62-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/vindr_62.png" class="img-fluid rounded" width="100%" height="auto" style=" min-height: 300px; max-height: 350px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Noisy multi-rater annotations in VinDR-CXR dataset</figcaption> </figure> </swiper-slide> </swiper-container> </div> <p>This results in multiple noisy object annotations originating from different annotators, i.e. multi-rater problem in object detection.</p> <hr style="height:10px;"> <h3 id="bayesian-detector-combination"><strong>Bayesian Detector Combination</strong></h3> <p>We propose a novel Bayesian Detector Combination (BDC) framework to more effectively train object detectors with only noisy multi-rater annotations, with the unique ability of automatically inferring the annotators’ label qualities. Unlike previous approaches, the proposed method is model-agnostic, requires no prior knowledge of the annotators’ skill level, and seamlessly integrates with existing object detection models.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/bdc-diagram-480.webp 480w,/assets/img/bdc_eccv/bdc-diagram-800.webp 800w,/assets/img/bdc_eccv/bdc-diagram-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/bdc-diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>At a high level, BDC models each annotators’ annotation accuracy in terms of bounding boxes as a Gaussian distribution with a Gaussian-Gamma prior and class labels as a multinomial distribution with a Dirichlet prior. During model training, we perform a many-to-one matching of each annotator’s annotation to the model output via a simple heuristic matching rule. The annotation-prediction matches are then used to update each annotators’ prior distributions with the mean-field variational Bayesian method. Then, the updated posterior distributions are used to aggregate all annotations matched to the same prediction to learn the object detector’s parameters. The process of optimizing the object detector’s parameters and updating the prior distributions is repeated iteratively until convergence.</p> <hr style="height:10px;"> <h3 id="experiments-results"><strong>Experiments Results</strong></h3> <p>To demonstrate the superiority, robustness and generalizability of BDC, our experiments span across three popular object detectors and includes several natural images and medical images datasets. Our extensive evaluation showed that BDC outperforms prior methods with negligible computation overhead, improving detection accuracy up to 12.7% AP50 when ground truth is available. Please see the <a href="https://arxiv.org/abs/2407.07958" rel="external nofollow noopener" target="_blank">paper</a> for the full results.</p> <h4 id="vindr-cxr"><strong>VinDR-CXR</strong></h4> <div class="container"> <div class="row"> <span>Comparison of aggregated labels on the VinDR-CXR chest radiograph dataset. For WBF-EARL, the number beside the class label is the annotators' level of agreement while for Crowd R-CNN and BDC, the number indicates the class probability.</span> </div> <div class="row"> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1428_na-480.webp 480w,/assets/img/bdc_eccv/1428_na-800.webp 800w,/assets/img/bdc_eccv/1428_na-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1428_na.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1428_mv-480.webp 480w,/assets/img/bdc_eccv/1428_mv-800.webp 800w,/assets/img/bdc_eccv/1428_mv-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1428_mv.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1428_earl-480.webp 480w,/assets/img/bdc_eccv/1428_earl-800.webp 800w,/assets/img/bdc_eccv/1428_earl-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1428_earl.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1428_crcnn-480.webp 480w,/assets/img/bdc_eccv/1428_crcnn-800.webp 800w,/assets/img/bdc_eccv/1428_crcnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1428_crcnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1428_bdc-480.webp 480w,/assets/img/bdc_eccv/1428_bdc-800.webp 800w,/assets/img/bdc_eccv/1428_bdc-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1428_bdc.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1623_na-480.webp 480w,/assets/img/bdc_eccv/1623_na-800.webp 800w,/assets/img/bdc_eccv/1623_na-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1623_na.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1623_mv-480.webp 480w,/assets/img/bdc_eccv/1623_mv-800.webp 800w,/assets/img/bdc_eccv/1623_mv-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1623_mv.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1623_earl-480.webp 480w,/assets/img/bdc_eccv/1623_earl-800.webp 800w,/assets/img/bdc_eccv/1623_earl-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1623_earl.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1623_crcnn-480.webp 480w,/assets/img/bdc_eccv/1623_crcnn-800.webp 800w,/assets/img/bdc_eccv/1623_crcnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1623_crcnn.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/1623_bdc-480.webp 480w,/assets/img/bdc_eccv/1623_bdc-800.webp 800w,/assets/img/bdc_eccv/1623_bdc-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/1623_bdc.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row text-center mb-3"> <div class="col px-2">No Aggregation</div> <div class="col px-2">Majority Voting</div> <div class="col px-2">WBF-EARL</div> <div class="col px-2">Crowd R-CNN</div> <div class="col px-2">BDC (ours)</div> </div> </div> <h4 id="voc-mix"><strong>VOC-MIX</strong></h4> <div class="container"> <div class="row"> <span>Comparison of aggregated labels on the VOC-MIX synthetic dataset. For WBF-EARL, the number beside the class label is the annotators' level of agreement while for Crowd R-CNN and BDC, the number indicates the class probability.</span> </div> <div class="row"> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_na-480.webp 480w,/assets/img/bdc_eccv/127_na-800.webp 800w,/assets/img/bdc_eccv/127_na-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_na.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_mv-480.webp 480w,/assets/img/bdc_eccv/127_mv-800.webp 800w,/assets/img/bdc_eccv/127_mv-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_mv.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_earl-480.webp 480w,/assets/img/bdc_eccv/127_earl-800.webp 800w,/assets/img/bdc_eccv/127_earl-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_earl.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_crcnn-480.webp 480w,/assets/img/bdc_eccv/127_crcnn-800.webp 800w,/assets/img/bdc_eccv/127_crcnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_crcnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_bdc-480.webp 480w,/assets/img/bdc_eccv/127_bdc-800.webp 800w,/assets/img/bdc_eccv/127_bdc-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_bdc.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/127_gt-480.webp 480w,/assets/img/bdc_eccv/127_gt-800.webp 800w,/assets/img/bdc_eccv/127_gt-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/127_gt.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_na-480.webp 480w,/assets/img/bdc_eccv/146_na-800.webp 800w,/assets/img/bdc_eccv/146_na-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_na.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_mv-480.webp 480w,/assets/img/bdc_eccv/146_mv-800.webp 800w,/assets/img/bdc_eccv/146_mv-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_mv.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_earl-480.webp 480w,/assets/img/bdc_eccv/146_earl-800.webp 800w,/assets/img/bdc_eccv/146_earl-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_earl.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_crcnn-480.webp 480w,/assets/img/bdc_eccv/146_crcnn-800.webp 800w,/assets/img/bdc_eccv/146_crcnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_crcnn.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_bdc-480.webp 480w,/assets/img/bdc_eccv/146_bdc-800.webp 800w,/assets/img/bdc_eccv/146_bdc-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_bdc.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col px-2"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/146_gt-480.webp 480w,/assets/img/bdc_eccv/146_gt-800.webp 800w,/assets/img/bdc_eccv/146_gt-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/146_gt.png" class="img-fluid rounded z-depth-1 mb-n2" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row text-center mb-3"> <div class="col px-2">No Aggregation</div> <div class="col px-2">Majority Voting</div> <div class="col px-2">WBF-EARL</div> <div class="col px-2">Crowd R-CNN</div> <div class="col px-2">BDC (ours)</div> <div class="col px-2">Ground truth</div> </div> </div> <h4 id="scability-and-robustness"><strong>Scability and Robustness</strong></h4> <p>We analyse the scability and Robustness of our method by varying the number of annotators and changing the percentage of noisy or poor-performing annotators. Our method consistently outperform other alternatives under all scenarios.</p> <div class="w-50 ml-0 mr-0 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/leg_title_abls-480.webp 480w,/assets/img/bdc_eccv/leg_title_abls-800.webp 800w,/assets/img/bdc_eccv/leg_title_abls-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/leg_title_abls.png" class="img-fluid rounded mb-n2" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true" centered-slides="true" autoplay-delay="5000"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/k_ablation-480.webp 480w,/assets/img/bdc_eccv/k_ablation-800.webp 800w,/assets/img/bdc_eccv/k_ablation-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/k_ablation.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Scalability of BDC</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bdc_eccv/nr_ablation-480.webp 480w,/assets/img/bdc_eccv/nr_ablation-800.webp 800w,/assets/img/bdc_eccv/nr_ablation-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/bdc_eccv/nr_ablation.png" class="img-fluid rounded" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Robustness of BDC</figcaption> </figure> </swiper-slide> </swiper-container> </div> <hr style="height:10px;"> <h3 id="presentation"><strong>Presentation</strong></h3> <div class="w-75 ml-0 mr-0 mx-auto"> <div class="embed-responsive embed-responsive-16by9"> <figure> <iframe src="https://www.youtube.com/embed/yddjKV1hmrI" class="embed-responsive-item rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto" title="Bayesian Detector Combination for Object Detection with Crowdsourced Annotations - ECCV 2024"></iframe> <figcaption class="caption">Poster presentation at ECCV 2024</figcaption> </figure> </div> </div> <hr style="height:10px;"> <h3 id="poster"><strong>Poster</strong></h3> <div class="container"> <iframe src="/assets/pdf/bdc_eccv_poster.pdf" class="w-100" height="700px"></iframe> </div> <hr style="height:10px;"> <h3 id="bibtex"><strong>BibTeX</strong></h3> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bdc2024tan</span><span class="p">,</span>
   <span class="na">title</span>     <span class="p">=</span> <span class="s">{Bayesian Detector Combination for Object Detection with Crowdsourced Annotations}</span><span class="p">,</span>
   <span class="na">author</span>    <span class="p">=</span> <span class="s">{Tan, Zhi Qin and Isupova, Olga and Carneiro, Gustavo and Zhu, Xiatian and Li, Yunpeng}</span><span class="p">,</span>
   <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Eur. Conf. Comput. Vis.}</span><span class="p">,</span>
   <span class="na">pages</span>     <span class="p">=</span> <span class="s">{329--346}</span><span class="p">,</span>
   <span class="na">year</span>      <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
   <span class="na">address</span>   <span class="p">=</span> <span class="s">{Milan, Italy}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 KCL TAI Group . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-element-bundle.min.js" integrity="sha256-BPrwikijIybg9OQC5SYFFqhBjERYOn97tCureFgYH1E=" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>